{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCNcwQxav4kisSiPeY6wmE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from zipfile import ZipFile\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import tensorflow_datasets as tfds"],"metadata":{"id":"c3Cs-VVdVb42","executionInfo":{"status":"ok","timestamp":1662628581008,"user_tz":-120,"elapsed":1157,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlFXnae0Uia1","executionInfo":{"status":"ok","timestamp":1662627777443,"user_tz":-120,"elapsed":19003,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}},"outputId":"f0dd4a61-f2ff-4db3-ca60-78c84cfa537e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Done unzipping Combined_Images.zip\n"]}],"source":["#JUPYTER VERSION\n","#comb_path = \"../Data/Combined_Images\"\n","\n","#GOOGLE COLAB VERSION\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Unzipping the dataset file facial-age.zip\n","\n","combined_images_path = \"/content/drive/MyDrive/Data/Combined_Images.zip\"\n","\n","with ZipFile(combined_images_path, 'r') as myzip:\n","    myzip.extractall(\"../content/Combined_Images\")\n","    print('Done unzipping Combined_Images.zip')\n","\n","comb_path = '../content/Combined_Images' \n","batch_size = 64"]},{"cell_type":"code","source":["train_ds = tf.keras.utils.image_dataset_from_directory(\n","  comb_path,\n","  validation_split=0.2,\n","  subset=\"training\", #If should be return the training set (80%) or the validation set (20%)\n","  seed=41, #Seed should guarantee that train_ds and val_ds doesn't have common images\n","  shuffle=True,\n","  image_size=(200, 200),\n","  batch_size=batch_size,\n","  color_mode='grayscale')\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  comb_path,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=41, \n","  shuffle=True,\n","  image_size=(200, 200),\n","  batch_size=batch_size,\n","  color_mode='grayscale')\n","\n","test_dataset = val_ds.take(53)\n","val_ds = val_ds.skip(53)\n","\n","print('Batches for training -->', train_ds.cardinality())\n","print('Batches for validating -->', val_ds.cardinality())\n","print('Batches for testing -->', test_dataset.cardinality())   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H24E0sFGXjU5","executionInfo":{"status":"ok","timestamp":1662628288067,"user_tz":-120,"elapsed":3994,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}},"outputId":"a0ab1dde-b6ff-4647-c2c8-1041888102aa"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 33884 files belonging to 8 classes.\n","Using 27108 files for training.\n","Found 33884 files belonging to 8 classes.\n","Using 6776 files for validation.\n","Batches for training --> tf.Tensor(424, shape=(), dtype=int64)\n","Batches for validating --> tf.Tensor(53, shape=(), dtype=int64)\n","Batches for testing --> tf.Tensor(53, shape=(), dtype=int64)\n"]}]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        rotation_range=25\n","        )\n","test_datagen = ImageDataGenerator(rescale=1./255)"],"metadata":{"id":"1Mb-R779U5wj","executionInfo":{"status":"ok","timestamp":1662627858238,"user_tz":-120,"elapsed":234,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def convert_tf_to_pd(ds, limit=32):\n","    \"\"\"\n","    Read data from Tensorflow dataset to Pandas dataframe\n","    :param ds:\n","    :param limit:\n","    :return:\n","    \"\"\"\n","    batch_iterator = ds.batch(limit).make_one_shot_iterator()\n","    with tf.Session() as sess:\n","        batch = batch_iterator.get_next()\n","        features_and_labels = sess.run(batch)\n","        samples = {\n","            **features_and_labels[0],\n","            'label': features_and_labels[1],\n","        }\n","\n","    return pd.DataFrame.from_dict(samples)"],"metadata":{"id":"fVTUfPE8ZRQ-","executionInfo":{"status":"ok","timestamp":1662628736448,"user_tz":-120,"elapsed":226,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5_v9B28OZtgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_generator = train_datagen.flow_from_dataframe(\n","        train_ds,\n","        target_size=(200, 200),\n","        batch_size=batch_size,\n","        class_mode='categorical'\n","        )\n","validation_generator = test_datagen.flow_from_dataframe(\n","        val_ds,\n","        target_size=(200, 200),\n","        batch_size=batch_size,\n","        class_mode='categorical'\n","        )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"id":"RUVu1Q0oV8xS","executionInfo":{"status":"error","timestamp":1662628358524,"user_tz":-120,"elapsed":839,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}},"outputId":"49ca56a0-8edb-4ff0-a6d9-4ef11947d40f"},"execution_count":6,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-3ad785a3f56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         )\n\u001b[1;32m      7\u001b[0m validation_generator = test_datagen.flow_from_dataframe(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m         validate_filenames=validate_filenames)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    131\u001b[0m                                                             \u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                                             interpolation)\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'copy'"]}]}]}