{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMyvkbURaO6BRzwfXAc79ko"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"92wpdpptQgbC","executionInfo":{"status":"ok","timestamp":1662464561978,"user_tz":-120,"elapsed":2277,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}}},"outputs":[],"source":["import tensorflow as tf\n","import keras\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from zipfile import ZipFile\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import regularizers"]},{"cell_type":"code","source":["#JUPYTER VERSION\n","#comb_path = \"../Data/Combined_Images\"\n","\n","#GOOGLE COLAB VERSION\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Unzipping the dataset file facial-age.zip\n","\n","combined_images_path = \"/content/drive/MyDrive/Data/Combined_Images.zip\"\n","\n","with ZipFile(combined_images_path, 'r') as myzip:\n","    myzip.extractall(\"../content/Combined_Images\")\n","    print('Done unzipping Combined_Images.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8n90ZrXRu-n","executionInfo":{"status":"ok","timestamp":1662464601203,"user_tz":-120,"elapsed":39231,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}},"outputId":"7777b37b-e3a4-4e90-acbe-9ed0d0fc5df3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Done unzipping Combined_Images.zip\n"]}]},{"cell_type":"code","source":["comb_path = '../content/Combined_Images' \n","batch_size = 64\n","\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","  comb_path,\n","  validation_split=0.2,\n","  subset=\"training\", #If should be return the training set (80%) or the validation set (20%)\n","  seed=41, #Seed should guarantee that train_ds and val_ds doesn't have common images\n","  shuffle=True,\n","  image_size=(200, 200),\n","  batch_size=batch_size,\n","  color_mode='grayscale')\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  comb_path,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=41, \n","  shuffle=True,\n","  image_size=(200, 200),\n","  batch_size=batch_size,\n","  color_mode='grayscale')\n","\n","test_dataset = val_ds.take(53)\n","val_ds = val_ds.skip(53)\n","\n","print('Batches for training -->', train_ds.cardinality())\n","print('Batches for validating -->', val_ds.cardinality())\n","print('Batches for testing -->', test_dataset.cardinality())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-5jdxafRxz2","executionInfo":{"status":"ok","timestamp":1662464607699,"user_tz":-120,"elapsed":6502,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}},"outputId":"aedb6b9b-da95-42a5-a5d0-35324e5d3ef5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 33884 files belonging to 8 classes.\n","Using 27108 files for training.\n","Found 33884 files belonging to 8 classes.\n","Using 6776 files for validation.\n","Batches for training --> tf.Tensor(424, shape=(), dtype=int64)\n","Batches for validating --> tf.Tensor(53, shape=(), dtype=int64)\n","Batches for testing --> tf.Tensor(53, shape=(), dtype=int64)\n"]}]},{"cell_type":"markdown","source":["## ALEXNET"],"metadata":{"id":"jcV2bVFrR5-3"}},{"cell_type":"code","source":["model4 = tf.keras.Sequential([\n","    tf.keras.layers.Rescaling(1./255, input_shape=(200, 200, 1)),\n","    tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(200,200,1)),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n","    tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n","    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(4096, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(4096, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(8, activation='softmax')\n","])\n","\n","#model.compile(optimizer=tf.keras.optimizers.Adam(),\n","              #loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","              #metrics=tf.keras.metrics.Accuracy())\n","\n","#Additionaly, if you do not one-hot encode your data, set sparse_categorical_crossentropy as loss and sparse_categorical_accuracy as metric.\n","model4.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n","\n","# Defining the early stop to monitor the validation loss to avoid overfitting.\n","early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n","\n","epochs=25\n","history = model4.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  callbacks=[early_stop],\n","  epochs=epochs,\n","  shuffle=True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YuebDpyVR7bP","executionInfo":{"status":"ok","timestamp":1662465382582,"user_tz":-120,"elapsed":774889,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}},"outputId":"419bd5b2-0023-4c03-89d4-d6738fead56f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","424/424 [==============================] - 56s 99ms/step - loss: 2.8574 - sparse_categorical_accuracy: 0.2176 - val_loss: 1.9688 - val_sparse_categorical_accuracy: 0.2408\n","Epoch 2/25\n","424/424 [==============================] - 39s 92ms/step - loss: 1.9504 - sparse_categorical_accuracy: 0.2458 - val_loss: 1.8950 - val_sparse_categorical_accuracy: 0.2503\n","Epoch 3/25\n","424/424 [==============================] - 39s 91ms/step - loss: 1.8848 - sparse_categorical_accuracy: 0.2668 - val_loss: 2.0308 - val_sparse_categorical_accuracy: 0.1823\n","Epoch 4/25\n","424/424 [==============================] - 39s 91ms/step - loss: 1.8566 - sparse_categorical_accuracy: 0.2807 - val_loss: 1.8079 - val_sparse_categorical_accuracy: 0.3050\n","Epoch 5/25\n","424/424 [==============================] - 39s 90ms/step - loss: 1.8227 - sparse_categorical_accuracy: 0.2914 - val_loss: 1.8876 - val_sparse_categorical_accuracy: 0.2686\n","Epoch 6/25\n","424/424 [==============================] - 38s 89ms/step - loss: 1.7790 - sparse_categorical_accuracy: 0.3076 - val_loss: 1.8523 - val_sparse_categorical_accuracy: 0.2485\n","Epoch 7/25\n","424/424 [==============================] - 38s 89ms/step - loss: 1.7175 - sparse_categorical_accuracy: 0.3307 - val_loss: 1.6622 - val_sparse_categorical_accuracy: 0.3404\n","Epoch 8/25\n","424/424 [==============================] - 38s 89ms/step - loss: 1.6717 - sparse_categorical_accuracy: 0.3416 - val_loss: 1.6485 - val_sparse_categorical_accuracy: 0.3460\n","Epoch 9/25\n","424/424 [==============================] - 38s 88ms/step - loss: 1.6225 - sparse_categorical_accuracy: 0.3603 - val_loss: 1.6085 - val_sparse_categorical_accuracy: 0.3593\n","Epoch 10/25\n","424/424 [==============================] - 37s 86ms/step - loss: 1.5747 - sparse_categorical_accuracy: 0.3800 - val_loss: 1.5582 - val_sparse_categorical_accuracy: 0.3753\n","Epoch 11/25\n","424/424 [==============================] - 37s 87ms/step - loss: 1.5436 - sparse_categorical_accuracy: 0.3898 - val_loss: 1.7831 - val_sparse_categorical_accuracy: 0.3094\n","Epoch 12/25\n","424/424 [==============================] - 38s 87ms/step - loss: 1.4746 - sparse_categorical_accuracy: 0.4092 - val_loss: 1.8358 - val_sparse_categorical_accuracy: 0.3369\n","Epoch 13/25\n","424/424 [==============================] - 37s 87ms/step - loss: 1.4392 - sparse_categorical_accuracy: 0.4255 - val_loss: 1.8752 - val_sparse_categorical_accuracy: 0.3097\n","Epoch 14/25\n","424/424 [==============================] - 37s 86ms/step - loss: 1.3928 - sparse_categorical_accuracy: 0.4377 - val_loss: 1.7527 - val_sparse_categorical_accuracy: 0.3413\n","Epoch 15/25\n","424/424 [==============================] - 37s 87ms/step - loss: 1.3371 - sparse_categorical_accuracy: 0.4596 - val_loss: 1.4395 - val_sparse_categorical_accuracy: 0.4128\n","Epoch 16/25\n","424/424 [==============================] - 37s 87ms/step - loss: 1.2826 - sparse_categorical_accuracy: 0.4798 - val_loss: 1.4567 - val_sparse_categorical_accuracy: 0.4134\n","Epoch 17/25\n","424/424 [==============================] - 37s 87ms/step - loss: 1.2314 - sparse_categorical_accuracy: 0.4980 - val_loss: 2.0581 - val_sparse_categorical_accuracy: 0.2858\n","Epoch 18/25\n","424/424 [==============================] - 37s 87ms/step - loss: 1.1965 - sparse_categorical_accuracy: 0.5081 - val_loss: 1.4986 - val_sparse_categorical_accuracy: 0.4238\n","Epoch 19/25\n","424/424 [==============================] - 37s 87ms/step - loss: 1.1129 - sparse_categorical_accuracy: 0.5393 - val_loss: 1.5685 - val_sparse_categorical_accuracy: 0.4128\n","Epoch 20/25\n","424/424 [==============================] - 37s 87ms/step - loss: 1.0548 - sparse_categorical_accuracy: 0.5609 - val_loss: 1.7597 - val_sparse_categorical_accuracy: 0.4031\n","Epoch 20: early stopping\n"]}]},{"cell_type":"code","source":["print(\"MODEL 4 --- ALEXNET\")\n","model4.evaluate(test_dataset)"],"metadata":{"id":"IQVzFInqXkek","executionInfo":{"status":"ok","timestamp":1662465386245,"user_tz":-120,"elapsed":3671,"user":{"displayName":"Luca Mag","userId":"06619506036873405402"}},"outputId":"f620a65c-4015-4c29-eb30-c49b6dea2f50","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["MODEL 4 --- ALEXNET\n","53/53 [==============================] - 4s 56ms/step - loss: 1.7779 - sparse_categorical_accuracy: 0.4092\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.7778868675231934, 0.4091981053352356]"]},"metadata":{},"execution_count":5}]}]}